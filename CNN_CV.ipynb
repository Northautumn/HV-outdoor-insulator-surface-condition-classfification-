{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_CV.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCflm00r-wYm","executionInfo":{"status":"ok","timestamp":1610191953938,"user_tz":-360,"elapsed":23682,"user":{"displayName":"Darkhan Baizhan","photoUrl":"","userId":"04672243568382651842"}},"outputId":"d1fbc6dd-869e-4da3-8c68-73c3c70502cb"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bOyp4Pd3bLln"},"source":["!pip install keras-tuner"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NuojxUY70r19"},"source":["import numpy as np\r\n","import pandas as pd\r\n","import tensorflow as tf\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras import layers\r\n","from keras.models import Sequential\r\n","from keras.optimizers import SGD\r\n","from keras.models import load_model\r\n","from sklearn.metrics import confusion_matrix\r\n","from sklearn.metrics import roc_auc_score\r\n","import kerastuner as kt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VzO5RIrvaiIV"},"source":["#Constants\r\n","\r\n","IMAGE_WIDTH= 128\r\n","IMAGE_HEIGHT= 128\r\n","IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\r\n","IMAGE_CHANNELS=3\r\n","batch_size = 32\r\n","data_dir = \"/content/drive/Shareddrives/A&D co./Conference Paper/Codes/2000_images\"\r\n","checkpoint_filepath = \"/content/drive/Shareddrives/A&D co./Conference Paper/Codes/CNN/\"\r\n","\r\n","\r\n","\r\n","results = []\r\n","img_gen = ImageDataGenerator(\r\n","rescale=1/255\r\n",")\r\n","\r\n","earlystop = tf.keras.callbacks.EarlyStopping(\r\n","    monitor = 'val_accuracy',\r\n","    mode = 'max',\r\n","    patience = 7\r\n","    verbose = 1,\r\n","    min_delta = 0.015\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yIjKXJ_ecvAS"},"source":["def evaluation(model,test_generator):\r\n","  index_to_cls = {v: k for k, v in test_generator.class_indices.items()}\r\n","  Y_pred = model.predict(test_generator)\r\n","  y_pred = np.argmax(Y_pred, axis=1)\r\n","  y_true = test_generator.classes\r\n","  y_pred_st = np.vectorize(index_to_cls.get)(y_pred)\r\n","  y_true_st = np.vectorize(index_to_cls.get)(test_generator.classes)\r\n","  roc = roc_auc_score(y_true, Y_pred[:,0])\r\n","  cm = confusion_matrix(y_true_st, y_pred_st, labels=np.unique(y_true_st)) \r\n","  TP = cm[0][0]\r\n","  FP = cm[0][1]\r\n","  FN = cm[1][0]\r\n","  TN = cm[1][1]\r\n","  return [TP,FP,FN,TN,roc]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8E0iGskKcy_u"},"source":["def build_model(hp):\r\n","  inputs = tf.keras.Input(shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\r\n","  x = inputs\r\n","  for i in range(hp.Int('conv_blocks', 3, 6)):\r\n","    filters = hp.Int('filters_' + str(i), 32, 256, step=32,default = 64)\r\n","    x = tf.keras.layers.Convolution2D(\r\n","        filters, kernel_size=(3, 3), padding='same')(x)\r\n","    x = tf.keras.layers.BatchNormalization()(x)\r\n","    x = tf.keras.layers.ReLU()(x)\r\n","    if hp.Choice('pooling_' + str(i), ['avg', 'max']) == 'max':\r\n","      x = tf.keras.layers.MaxPool2D()(x)\r\n","    else:\r\n","      x = tf.keras.layers.AvgPool2D()(x)\r\n","  if hp.Choice('Global vs Flatten', ['global', 'flatten']) == 'global':\r\n","     x = tf.keras.layers.GlobalAvgPool2D()(x)\r\n","  else:\r\n","      x = tf.keras.layers.Flatten()(x)\r\n","  x = tf.keras.layers.Dense(\r\n","      hp.Int('hidden_size', 32, 256, step=16, default=128),\r\n","      activation='relu')(x)\r\n","  x = tf.keras.layers.Dropout(\r\n","      hp.Float('dropout', 0, 0.5, step=0.1, default=0.5))(x)\r\n","  if hp.Choice('Sigm vs Softmax', ['softmax', 'sigmoid']) == 'softmax':\r\n","     outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\r\n","     loss = 'sparse_categorical_crossentropy'\r\n","  else:\r\n","      outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\r\n","      loss = 'binary_crossentropy'\r\n","\r\n","  model = tf.keras.Model(inputs, outputs)\r\n","  if hp.Choice('Adam vs SGD', ['adam', 'sgd']) == 'adam':\r\n","    model.compile(\r\n","      optimizer=tf.keras.optimizers.Adam(\r\n","        hp.Float('learning_rate_Adam', 1e-6, 1e-2, sampling='log')),\r\n","      loss=loss, \r\n","      metrics=[\"accuracy\",\r\n","                ])\r\n","  else:\r\n","        opt = SGD(lr=hp.Float('learning_rate_SGD', 1e-6, 1e-2, sampling='log'),momentum = hp.Choice('momentum',values = [0.9,0.8,0.7]))\r\n","        model.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\",\r\n","                                                                      ])\r\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E0mPmzyd-slp"},"source":["#Reading and Shuffling csv that contain filenames and label\r\n","df1 = pd.read_csv(\"/content/drive/Shareddrives/A&D co./Conference Paper/Codes/2000_labels.csv\")\r\n","from sklearn.utils import shuffle\r\n","df2 = shuffle(df1, random_state = 15)\r\n","df2.reset_index(inplace = True, drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"esiB0YeBc-NN"},"source":["tuner = kt.Hyperband(build_model,\r\n","                     objective = 'val_accuracy', \r\n","                     max_epochs = 50,\r\n","                     factor = 2,\r\n","                     project_name = 'HyperBand_CNN')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcLELwxMzpO8"},"source":["# 5-fold cross validaiton\r\n","for case in range(5):\r\n","  one,two,three,four,five= np.split(df2, [int(.20*len(df2)),int(.40*len(df2)),int(.60*len(df2)), int(.80*len(df2))])\r\n","  holdouts = [one,two,three,four,five]\r\n","  test = holdouts[case]\r\n","  frames = holdouts[:case] + holdouts[case+1:]\r\n","  df3 = pd.concat(frames)\r\n","  df4 = shuffle(df3, random_state = case*10)\r\n","  df4.reset_index(inplace = True, drop=True)\r\n","  train,validate = np.split(df4,[int(.75*len(df4))])\r\n","\r\n","  train_generator = img_gen.flow_from_dataframe(\r\n","            train, \r\n","            directory = data_dir,\r\n","            batch_size=batch_size,\r\n","            x_col='filename',\r\n","            y_col='label',\r\n","            target_size=IMAGE_SIZE,\r\n","            class_mode='binary',\r\n","            shuffle = True\r\n","    )\r\n","    \r\n","  validation_generator = img_gen.flow_from_dataframe(\r\n","            validate, \r\n","            directory = data_dir,\r\n","            batch_size=1,\r\n","            x_col='filename',\r\n","            y_col='label',\r\n","            target_size=IMAGE_SIZE,\r\n","            class_mode='binary',\r\n","            shuffle = True\r\n","                )\r\n","  test_generator = img_gen.flow_from_dataframe(\r\n","            test, \r\n","            directory = data_dir,\r\n","            batch_size=1,\r\n","            x_col='filename',\r\n","            y_col='label',\r\n","            target_size=IMAGE_SIZE,\r\n","            class_mode='binary',\r\n","            shuffle = False\r\n","    )\r\n","  tuner.search(train_generator, validation_data = validation_generator,verbose = 1, callbacks = [earlystop]) #checkpoint\r\n","  best_model = tuner.get_best_models(num_models=5)[0]\r\n","  best_model.save(checkpoint_filepath+\"Model_CNN/best_model_\"+str(case)+\".h5\")\r\n","  r = evaluation(best_model,test_generator)\r\n","  print(r)\r\n","  results.append(r)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"adPtwBN92bwT"},"source":["new_result = []\r\n","for holdout in results:\r\n","  accuracy = (holdout[0]+holdout[3])/(holdout[0]+holdout[1]+holdout[2]+holdout[3])\r\n","  precision = holdout[0]/(holdout[0]+holdout[1])\r\n","  recall = holdout[0]/(holdout[0]+holdout[2])\r\n","  f1_score = (2*precision*recall)/(precision+recall)\r\n","  holdout.append(accuracy)\r\n","  holdout.append(precision)\r\n","  holdout.append(recall)\r\n","  holdout.append(f1_score)\r\n","  new_results.append(holdout)\r\n","rs = pd.DataFrame(new_result, columns =['TP','FP','FN','TN','AUC ROC','Accuracy','Precision','Recall','F1_score'])\r\n","rs.to_csv(path_or_buf = checkpoint_filepath+\"CNN_CV_Results.csv\"  ,index=False)"],"execution_count":null,"outputs":[]}]}